services:
  app-runner:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: app-runner
    environment:
      - WEAVIATE_HOST=weaviate
      - WEAVIATE_PORT=8080
      - WEAVIATE_GRPC_PORT=50051
      # Logging settings - output to docker compose logs
      - LOG_LEVEL=INFO
      - LOG_TO_FILE=false
      - PYTHONUNBUFFERED=1
      # Embedding performance settings
      - EMBEDDING_BATCH_SIZE=64
      - ENCODE_BATCH_SIZE=128
      # NVIDIA GPU settings
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
     # - OPENAI_MODEL_ID
     # - OPENAI_BASE_URL
     # - OPENAI_API_KEY
    #depends_on:
    #  -  weaviate
    volumes:
      - .:/app
      - ./RepoKnowledgeGraphLib:/data/repo  # <-- Replace ./RepoKnowledgeGraphLib with your actual path
    # Default command runs test_transformers.py; override with e.g. `docker compose -f docker-compose-transformers.yml run app-runner python test_vllm.py`
    command: python make_swe_knowledge_graphs.py
    # GPU enablement for docker compose (requires nvidia-container-toolkit)
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
